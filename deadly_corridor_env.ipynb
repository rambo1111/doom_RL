{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting VizDoom Up and Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import vizdoom for game env\n",
    "from vizdoom import * \n",
    "# Import random for action sampling\n",
    "import random\n",
    "# Import time for sleeping\n",
    "import time \n",
    "# Import numpy for identity matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.   0.   0.  -1.]\n"
     ]
    }
   ],
   "source": [
    "# Setup game\n",
    "game = DoomGame()\n",
    "game.load_config('configs/deadly_corridor.cfg')\n",
    "game.init()\n",
    "print(game.get_state().game_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the set of actions we can take in the environment\n",
    "actions = np.identity(7, dtype=np.uint8)\n",
    "random.choice(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = game.get_state().game_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.   0.   0.  -1.]\n"
     ]
    }
   ],
   "source": [
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.   0.   0.  -1.]\n",
      "[100.   0.   0.  52.]\n",
      "[100.   0.   0.  52.]\n",
      "[100.   0.   0.  52.]\n",
      "[100.   0.   0.  52.]\n",
      "[100.   0.   0.  52.]\n",
      "[100.   0.   0.  51.]\n",
      "[100.   0.   0.  51.]\n",
      "[100.   0.   0.  51.]\n",
      "[100.   0.   0.  51.]\n",
      "[100.   0.   0.  51.]\n",
      "[100.   0.   0.  51.]\n",
      "[100.   0.   0.  50.]\n",
      "[100.   0.   0.  50.]\n",
      "[100.   0.   0.  50.]\n",
      "[100.   0.   0.  50.]\n",
      "[72. 28.  0. 50.]\n",
      "[72. 28.  0. 50.]\n",
      "[72. 28.  0. 50.]\n",
      "[72. 28.  0. 49.]\n",
      "[72. 28.  0. 49.]\n",
      "[72. 28.  0. 49.]\n",
      "[72. 28.  0. 49.]\n",
      "[72. 28.  0. 48.]\n",
      "[72. 28.  0. 48.]\n",
      "[72. 28.  0. 48.]\n",
      "[72. 28.  0. 48.]\n",
      "[72. 28.  0. 48.]\n",
      "[72. 28.  0. 48.]\n",
      "[72. 28.  0. 48.]\n",
      "[72. 28.  0. 48.]\n",
      "[72. 28.  0. 48.]\n",
      "[72. 28.  0. 48.]\n",
      "[72. 28.  0. 48.]\n",
      "[72. 28.  0. 48.]\n",
      "[72. 28.  0. 48.]\n",
      "[72. 28.  0. 48.]\n",
      "[72. 28.  0. 48.]\n",
      "[72. 28.  0. 48.]\n",
      "[72. 28.  1. 47.]\n",
      "[72. 28.  1. 47.]\n",
      "[44. 56.  1. 47.]\n",
      "[44. 56.  1. 47.]\n",
      "[44. 56.  1. 47.]\n",
      "[44. 56.  1. 46.]\n",
      "[44. 56.  1. 46.]\n",
      "[44. 56.  1. 46.]\n",
      "[44. 56.  1. 46.]\n",
      "[44. 56.  1. 46.]\n",
      "[44. 56.  1. 46.]\n",
      "[44. 56.  1. 46.]\n",
      "[44. 56.  1. 46.]\n",
      "[44. 56.  1. 46.]\n",
      "[44. 56.  1. 46.]\n",
      "[44. 56.  1. 46.]\n",
      "[44. 56.  1. 46.]\n",
      "[44. 56.  1. 46.]\n",
      "[44. 56.  1. 46.]\n",
      "[44. 56.  1. 46.]\n",
      "[44. 56.  1. 46.]\n",
      "[44. 56.  1. 45.]\n",
      "[44. 56.  1. 45.]\n",
      "[22. 78.  1. 45.]\n",
      "[22. 78.  1. 45.]\n",
      "[22. 78.  1. 45.]\n",
      "[22. 78.  1. 45.]\n",
      "[22. 78.  1. 45.]\n",
      "[22. 78.  1. 45.]\n",
      "[22. 78.  1. 45.]\n",
      "[22. 78.  1. 45.]\n",
      "[22. 78.  1. 44.]\n",
      "[22. 78.  1. 44.]\n",
      "[22. 78.  1. 44.]\n",
      "[22. 78.  1. 44.]\n",
      "[22. 78.  1. 44.]\n",
      "[22. 78.  1. 44.]\n",
      "[22. 78.  1. 44.]\n",
      "[22. 78.  1. 44.]\n",
      "[22. 78.  1. 44.]\n",
      "[20. 80.  1. 44.]\n",
      "[20. 80.  1. 44.]\n",
      "[20. 80.  1. 44.]\n",
      "[20. 80.  1. 43.]\n",
      "[20. 80.  1. 43.]\n",
      "[20. 80.  1. 43.]\n",
      "[20. 80.  1. 42.]\n",
      "[20. 80.  1. 42.]\n",
      "[20. 80.  1. 42.]\n",
      "[20. 80.  1. 42.]\n",
      "[20. 80.  1. 41.]\n",
      "[20. 80.  1. 41.]\n",
      "[20. 80.  1. 41.]\n",
      "[20. 80.  1. 41.]\n",
      "[20. 80.  1. 41.]\n",
      "[20. 80.  1. 40.]\n",
      "[20. 80.  1. 40.]\n",
      "[20. 80.  1. 40.]\n",
      "[20. 80.  1. 40.]\n",
      "[ 4. 96.  1. 40.]\n",
      "[ 4. 96.  1. 40.]\n",
      "[ 4. 96.  1. 40.]\n",
      "[ 4. 96.  1. 39.]\n",
      "[ 4. 96.  1. 39.]\n",
      "[ 4. 96.  1. 39.]\n",
      "[ 4. 96.  1. 39.]\n",
      "[ 4. 96.  1. 39.]\n",
      "[ 4. 96.  1. 39.]\n",
      "[ 4. 96.  1. 39.]\n",
      "[ 4. 96.  1. 39.]\n",
      "[ 4. 96.  1. 39.]\n",
      "[ 4. 96.  1. 39.]\n",
      "[ 4. 96.  1. 39.]\n",
      "[ 4. 96.  1. 39.]\n",
      "[ 4. 96.  1. 39.]\n",
      "Result: 97.94845581054688\n"
     ]
    }
   ],
   "source": [
    "# Loop through episodes \n",
    "episodes = 1\n",
    "for episode in range(episodes): \n",
    "    # Create a new episode or game \n",
    "    game.new_episode()\n",
    "    # Check the game isn't done \n",
    "    while not game.is_episode_finished(): \n",
    "        # Get the game state \n",
    "        state = game.get_state()\n",
    "        # Get the game image \n",
    "        img = state.screen_buffer\n",
    "        # Get the game variables - anmo\n",
    "        info = state.game_variables\n",
    "        print(info)\n",
    "        # Take an action\n",
    "        reward = game.make_action(random.choice(actions),4) # When our agent will take action it will skip 4 frames after taking the action.\n",
    "        time.sleep(0.02)\n",
    "    print('Result:', game.get_total_reward())\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Converting it to a Gym Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import environment base class from OpenAI Gym\n",
    "from gym import Env\n",
    "# Import gym spaces \n",
    "from gym.spaces import Discrete, Box\n",
    "# Import opencv \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[Discrete(7).sample()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Box(low=0, high=10, shape=(320,240), dtype=np.uint8).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vizdoom OpenAI Gym Environment\n",
    "class VizDoomGym(Env): \n",
    "    # Function that is called when we start the env\n",
    "    def __init__(self, render=False, doom_skill=1): \n",
    "        # Inherit from Env\n",
    "        super().__init__()\n",
    "        # Setup the game \n",
    "        self.game = DoomGame()\n",
    "        self.game.load_config('configs/deadly_corridor.cfg')\n",
    "        \n",
    "        # Render frame logic\n",
    "        self.game.set_window_visible(render)\n",
    "                \n",
    "        # Create the action space and observation space\n",
    "        self.observation_space = Box(low=0, high=255, shape=(100,160,1), dtype=np.uint8) \n",
    "        self.action_space = Discrete(7)\n",
    "        \n",
    "        # Game variables: HEALTH DAMAGE_TAKEN HITCOUNT SELECTED_WEAPON_AMMO\n",
    "        self.damage_taken = 0\n",
    "        self.hitcount = 0\n",
    "        self.ammo = 52 # CHANGED\n",
    "\n",
    "        # Skill level can now be set during initialization\n",
    "        self.game.set_doom_skill(doom_skill)\n",
    "\n",
    "        # Start the game \n",
    "        self.game.init()\n",
    "        \n",
    "    # Setting up the doom_skill\n",
    "    def set_skill_level(self, skill_level):\n",
    "        self.doom_skill = skill_level\n",
    "        self.game.close()  # Close the existing game instance\n",
    "        self.game = DoomGame()  # Create a new game instance\n",
    "        self.game.load_config('configs/deadly_corridor.cfg')\n",
    "        self.game.set_doom_skill(skill_level)\n",
    "\n",
    "\n",
    "    # This is how we take a step in the environment\n",
    "    def step(self, action):\n",
    "        # Specify action and take step \n",
    "        actions = np.identity(7)\n",
    "        movement_reward = self.game.make_action(actions[action], 4) \n",
    "        \n",
    "        reward = 0 \n",
    "        # Get all the other stuff we need to retun \n",
    "        if self.game.get_state(): \n",
    "            state = self.game.get_state().screen_buffer\n",
    "            state = self.grayscale(state)\n",
    "            \n",
    "            # Reward shaping\n",
    "            game_variables = self.game.get_state().game_variables\n",
    "            health, damage_taken, hitcount, ammo = game_variables\n",
    "            \n",
    "            # Calculate reward deltas\n",
    "            damage_taken_delta = -damage_taken + self.damage_taken\n",
    "            self.damage_taken = damage_taken\n",
    "            hitcount_delta = hitcount - self.hitcount\n",
    "            self.hitcount = hitcount\n",
    "            ammo_delta = ammo - self.ammo\n",
    "            self.ammo = ammo\n",
    "            \n",
    "            reward = movement_reward + damage_taken_delta*10 + hitcount_delta*200  + ammo_delta*5 \n",
    "            info = ammo\n",
    "        else: \n",
    "            state = np.zeros(self.observation_space.shape)\n",
    "            info = 0 \n",
    "        \n",
    "        info = {\"info\":info}\n",
    "        done = self.game.is_episode_finished()\n",
    "        \n",
    "        return state, reward, done, info \n",
    "    \n",
    "    # Define how to render the game or environment \n",
    "    def render(self): \n",
    "        pass\n",
    "    \n",
    "    # What happens when we start a new game \n",
    "    def reset(self): \n",
    "        self.game.new_episode()\n",
    "        state = self.game.get_state().screen_buffer\n",
    "        return self.grayscale(state)\n",
    "    \n",
    "    # Grayscale the game frame and resize it \n",
    "    def grayscale(self, observation):\n",
    "        gray = cv2.cvtColor(np.moveaxis(observation, 0, -1), cv2.COLOR_BGR2GRAY)\n",
    "        resize = cv2.resize(gray, (160,100), interpolation=cv2.INTER_CUBIC)\n",
    "        state = np.reshape(resize, (100,160,1))\n",
    "        return state\n",
    "    \n",
    "    # Call to close down the game\n",
    "    def close(self): \n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VizDoomGym(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. View Game State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(state, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment Cheker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Environment checker\n",
    "from stable_baselines3.common import env_checker\n",
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Setup Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os for file nav\n",
    "import os \n",
    "# Import callback class from sb3\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './models/models_deadly_corridor'\n",
    "LOG_DIR = './logs/log_deadly_corridor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=140000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ppo for training\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non rendered environment\n",
    "env = VizDoomGym(doom_skill=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/log_deadly_corridor\\PPO_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 218      |\n",
      "|    ep_rew_mean     | 94.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 45       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 182      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 212        |\n",
      "|    ep_rew_mean          | 143        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 42         |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 386        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00390896 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.94      |\n",
      "|    explained_variance   | -2.84e-05  |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 25.8       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.00414   |\n",
      "|    value_loss           | 3.41e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 171         |\n",
      "|    ep_rew_mean          | 165         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 586         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002919653 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.0141      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 4.05e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    value_loss           | 3.9e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 156          |\n",
      "|    ep_rew_mean          | 210          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 780          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037028994 |\n",
      "|    clip_fraction        | 0.266        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.034        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.26e+04     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    value_loss           | 5.43e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 141          |\n",
      "|    ep_rew_mean          | 274          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 41           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 979          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030515692 |\n",
      "|    clip_fraction        | 0.239        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.0629       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 426          |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 4.46e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 117         |\n",
      "|    ep_rew_mean          | 302         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 1176        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004673474 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.0804      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.02e+03    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    value_loss           | 6.65e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 98.8         |\n",
      "|    ep_rew_mean          | 388          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 41           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 1377         |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032631964 |\n",
      "|    clip_fraction        | 0.246        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.122        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.12e+04     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    value_loss           | 6.48e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 86           |\n",
      "|    ep_rew_mean          | 464          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 41           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 1580         |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038604196 |\n",
      "|    clip_fraction        | 0.263        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.83        |\n",
      "|    explained_variance   | 0.159        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    value_loss           | 6.96e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 80.2         |\n",
      "|    ep_rew_mean          | 482          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 41           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 1777         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035823542 |\n",
      "|    clip_fraction        | 0.261        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.8         |\n",
      "|    explained_variance   | 0.203        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 4.48e+03     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.000413    |\n",
      "|    value_loss           | 8.06e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 87.4        |\n",
      "|    ep_rew_mean          | 467         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 1974        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005288989 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.21e+03    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | 0.000498    |\n",
      "|    value_loss           | 7.87e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 81.7         |\n",
      "|    ep_rew_mean          | 512          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 41           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 2167         |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069360826 |\n",
      "|    clip_fraction        | 0.358        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.79        |\n",
      "|    explained_variance   | 0.279        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.06e+03     |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | 0.000827     |\n",
      "|    value_loss           | 7.34e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 84.3         |\n",
      "|    ep_rew_mean          | 581          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 41           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 2366         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054451087 |\n",
      "|    clip_fraction        | 0.301        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.72        |\n",
      "|    explained_variance   | 0.303        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.29e+03     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | 0.00171      |\n",
      "|    value_loss           | 7.65e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73.7        |\n",
      "|    ep_rew_mean          | 579         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 2574        |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012185677 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 4.51e+03    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | 0.00184     |\n",
      "|    value_loss           | 6.99e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 74.6       |\n",
      "|    ep_rew_mean          | 551        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 41         |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 2778       |\n",
      "|    total_timesteps      | 114688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00415833 |\n",
      "|    clip_fraction        | 0.311      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.7       |\n",
      "|    explained_variance   | 0.34       |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 1.39e+03   |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | 0.00162    |\n",
      "|    value_loss           | 7.64e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69.8        |\n",
      "|    ep_rew_mean          | 552         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 3006        |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004281206 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 3.55e+03    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | 0.0031      |\n",
      "|    value_loss           | 7.9e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 65.1         |\n",
      "|    ep_rew_mean          | 614          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 40           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 3258         |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086465925 |\n",
      "|    clip_fraction        | 0.351        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.67        |\n",
      "|    explained_variance   | 0.361        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.96e+03     |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | 0.00208      |\n",
      "|    value_loss           | 8.36e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 59.3        |\n",
      "|    ep_rew_mean          | 663         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 3517        |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005996881 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 6.30e+03    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | 0.00414     |\n",
      "|    value_loss           | 8.45e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64           |\n",
      "|    ep_rew_mean          | 704          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 39           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 3718         |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042355554 |\n",
      "|    clip_fraction        | 0.282        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.5         |\n",
      "|    explained_variance   | 0.39         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.8e+03      |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | 0.00359      |\n",
      "|    value_loss           | 9.39e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 63.7        |\n",
      "|    ep_rew_mean          | 629         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 3772        |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006990472 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 3.44e+03    |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | 0.00355     |\n",
      "|    value_loss           | 8.77e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 58.3         |\n",
      "|    ep_rew_mean          | 610          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 41           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 3987         |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049504973 |\n",
      "|    clip_fraction        | 0.367        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.53        |\n",
      "|    explained_variance   | 0.395        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 3.36e+03     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | 0.00425      |\n",
      "|    value_loss           | 8.83e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 53.9        |\n",
      "|    ep_rew_mean          | 669         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 4177        |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004701061 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 6.19e+03    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | 0.00333     |\n",
      "|    value_loss           | 9.45e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 52.4        |\n",
      "|    ep_rew_mean          | 704         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 4348        |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005207328 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 7.09e+03    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | 0.00305     |\n",
      "|    value_loss           | 1.02e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 48.8         |\n",
      "|    ep_rew_mean          | 695          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 4403         |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068592913 |\n",
      "|    clip_fraction        | 0.246        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0.42         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.95e+03     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | 0.00427      |\n",
      "|    value_loss           | 1.01e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 53          |\n",
      "|    ep_rew_mean          | 747         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 4525        |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007039952 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 4.19e+03    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.00426     |\n",
      "|    value_loss           | 1.09e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 47.7         |\n",
      "|    ep_rew_mean          | 765          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 44           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 4571         |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057123275 |\n",
      "|    clip_fraction        | 0.235        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0.417        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 8.75e+03     |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | 0.00477      |\n",
      "|    value_loss           | 9.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 47           |\n",
      "|    ep_rew_mean          | 748          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 4628         |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082539385 |\n",
      "|    clip_fraction        | 0.237        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.43         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.96e+03     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | 0.00429      |\n",
      "|    value_loss           | 1.07e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 47.4        |\n",
      "|    ep_rew_mean          | 765         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 4793        |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004294218 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 4.36e+03    |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | 0.00538     |\n",
      "|    value_loss           | 1.16e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 49.6         |\n",
      "|    ep_rew_mean          | 784          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 4971         |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053044627 |\n",
      "|    clip_fraction        | 0.198        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.39e+03     |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | 0.0046       |\n",
      "|    value_loss           | 1.11e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 49.2        |\n",
      "|    ep_rew_mean          | 796         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 5151        |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005158349 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 9.32e+03    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | 0.00409     |\n",
      "|    value_loss           | 1.09e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 47           |\n",
      "|    ep_rew_mean          | 760          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 5331         |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071784607 |\n",
      "|    clip_fraction        | 0.209        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 3.95e+03     |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | 0.00319      |\n",
      "|    value_loss           | 1.08e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 44           |\n",
      "|    ep_rew_mean          | 762          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 5516         |\n",
      "|    total_timesteps      | 253952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035924772 |\n",
      "|    clip_fraction        | 0.176        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | 0.00434      |\n",
      "|    value_loss           | 1.1e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 45.8         |\n",
      "|    ep_rew_mean          | 787          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 5697         |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057183644 |\n",
      "|    clip_fraction        | 0.193        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.984       |\n",
      "|    explained_variance   | 0.448        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.86e+03     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | 0.00483      |\n",
      "|    value_loss           | 1.2e+04      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 42.2        |\n",
      "|    ep_rew_mean          | 812         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 5874        |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009116165 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.987      |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.29e+03    |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | 0.00416     |\n",
      "|    value_loss           | 1.18e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 46.2         |\n",
      "|    ep_rew_mean          | 886          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 6054         |\n",
      "|    total_timesteps      | 278528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072700744 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.835       |\n",
      "|    explained_variance   | 0.445        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.28e+03     |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | 0.00337      |\n",
      "|    value_loss           | 1.27e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 42.9         |\n",
      "|    ep_rew_mean          | 823          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 45           |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 6233         |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043119113 |\n",
      "|    clip_fraction        | 0.169        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.842       |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 9.11e+03     |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | 0.00474      |\n",
      "|    value_loss           | 1.23e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 42.4        |\n",
      "|    ep_rew_mean          | 837         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 6408        |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005307873 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.868      |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 9.83e+03    |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | 0.00595     |\n",
      "|    value_loss           | 1.26e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 43.1         |\n",
      "|    ep_rew_mean          | 857          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 45           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 6589         |\n",
      "|    total_timesteps      | 303104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035196892 |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.801       |\n",
      "|    explained_variance   | 0.449        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 4.01e+03     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | 0.00345      |\n",
      "|    value_loss           | 1.28e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 41.7         |\n",
      "|    ep_rew_mean          | 928          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 6756         |\n",
      "|    total_timesteps      | 311296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055825645 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.772       |\n",
      "|    explained_variance   | 0.444        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.75e+03     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | 0.00384      |\n",
      "|    value_loss           | 1.27e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 42.3        |\n",
      "|    ep_rew_mean          | 1.04e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 6806        |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003955825 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.664      |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 6.2e+03     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | 0.00286     |\n",
      "|    value_loss           | 1.33e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 41.4         |\n",
      "|    ep_rew_mean          | 1.02e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 47           |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 6853         |\n",
      "|    total_timesteps      | 327680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028479092 |\n",
      "|    clip_fraction        | 0.0904       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.573       |\n",
      "|    explained_variance   | 0.423        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 9.89e+03     |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | 0.00442      |\n",
      "|    value_loss           | 1.39e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 41.9        |\n",
      "|    ep_rew_mean          | 1.03e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 6899        |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009985238 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.556      |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.03e+04    |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | 0.0042      |\n",
      "|    value_loss           | 1.47e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 42.3        |\n",
      "|    ep_rew_mean          | 1.07e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 6946        |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003332507 |\n",
      "|    clip_fraction        | 0.0962      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.524      |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.02e+04    |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | 0.00498     |\n",
      "|    value_loss           | 1.38e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 43.4        |\n",
      "|    ep_rew_mean          | 1.11e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 6993        |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002908906 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.457      |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 7.64e+03    |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | 0.00531     |\n",
      "|    value_loss           | 1.28e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 41.8         |\n",
      "|    ep_rew_mean          | 1.13e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 7040         |\n",
      "|    total_timesteps      | 360448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024844825 |\n",
      "|    clip_fraction        | 0.0849       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.463       |\n",
      "|    explained_variance   | 0.438        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 7.97e+03     |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | 0.00435      |\n",
      "|    value_loss           | 1.31e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 42.7        |\n",
      "|    ep_rew_mean          | 1.11e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 7088        |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004630251 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.425      |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 3.47e+03    |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | 0.00424     |\n",
      "|    value_loss           | 1.42e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 42.9        |\n",
      "|    ep_rew_mean          | 1.18e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 7143        |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003062503 |\n",
      "|    clip_fraction        | 0.0856      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.402      |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 7.08e+03    |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | 0.00456     |\n",
      "|    value_loss           | 1.3e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.5        |\n",
      "|    ep_rew_mean          | 1.19e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 7203        |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005638597 |\n",
      "|    clip_fraction        | 0.0681      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.375      |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 8.36e+03    |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | 0.00411     |\n",
      "|    value_loss           | 1.31e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.5        |\n",
      "|    ep_rew_mean          | 1.28e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 7259        |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004486737 |\n",
      "|    clip_fraction        | 0.0711      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.381      |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 5.14e+03    |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | 0.00439     |\n",
      "|    value_loss           | 1.22e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 42.7         |\n",
      "|    ep_rew_mean          | 1.28e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 7347         |\n",
      "|    total_timesteps      | 401408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019130078 |\n",
      "|    clip_fraction        | 0.0647       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.323       |\n",
      "|    explained_variance   | 0.407        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.77e+03     |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | 0.00354      |\n",
      "|    value_loss           | 1.37e+04     |\n",
      "------------------------------------------\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/log_deadly_corridor\\PPO_2\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33       |\n",
      "|    ep_rew_mean     | 900      |\n",
      "| time/              |          |\n",
      "|    fps             | 68       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 118      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 34           |\n",
      "|    ep_rew_mean          | 968          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 350          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022646168 |\n",
      "|    clip_fraction        | 0.0482       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.235       |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 8.38e+03     |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | 0.00278      |\n",
      "|    value_loss           | 2.01e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.6        |\n",
      "|    ep_rew_mean          | 919         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 579         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001932634 |\n",
      "|    clip_fraction        | 0.042       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.221      |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.12e+04    |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | 0.00317     |\n",
      "|    value_loss           | 2e+04       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32           |\n",
      "|    ep_rew_mean          | 841          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 39           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 820          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046169125 |\n",
      "|    clip_fraction        | 0.0576       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.235       |\n",
      "|    explained_variance   | 0.443        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.01e+03     |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | 0.00532      |\n",
      "|    value_loss           | 2e+04        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.3        |\n",
      "|    ep_rew_mean          | 913         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 1020        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004587866 |\n",
      "|    clip_fraction        | 0.06        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.247      |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.62e+04    |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | 0.00495     |\n",
      "|    value_loss           | 2.03e+04    |\n",
      "-----------------------------------------\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/log_deadly_corridor\\PPO_3\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 34.3     |\n",
      "|    ep_rew_mean     | 968      |\n",
      "| time/              |          |\n",
      "|    fps             | 41       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 196      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.5        |\n",
      "|    ep_rew_mean          | 946         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 413         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007536158 |\n",
      "|    clip_fraction        | 0.0425      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.17       |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.22e+04    |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | 0.00435     |\n",
      "|    value_loss           | 1.77e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 34.1         |\n",
      "|    ep_rew_mean          | 905          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 37           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 654          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014326519 |\n",
      "|    clip_fraction        | 0.0412       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.156       |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 4.54e+03     |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | 0.00514      |\n",
      "|    value_loss           | 1.81e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 35.3         |\n",
      "|    ep_rew_mean          | 952          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 36           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 887          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034691733 |\n",
      "|    clip_fraction        | 0.0423       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.156       |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.32e+04     |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | 0.00477      |\n",
      "|    value_loss           | 1.76e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 34.2         |\n",
      "|    ep_rew_mean          | 952          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 35           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 1154         |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008039654 |\n",
      "|    clip_fraction        | 0.0347       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.137       |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.88e+03     |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | 0.00407      |\n",
      "|    value_loss           | 1.69e+04     |\n",
      "------------------------------------------\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/log_deadly_corridor\\PPO_4\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 35.1     |\n",
      "|    ep_rew_mean     | 962      |\n",
      "| time/              |          |\n",
      "|    fps             | 35       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 230      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 34.1         |\n",
      "|    ep_rew_mean          | 953          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 33           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 485          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011022189 |\n",
      "|    clip_fraction        | 0.0413       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.153       |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.34e+04     |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | 0.00399      |\n",
      "|    value_loss           | 1.7e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 34.2         |\n",
      "|    ep_rew_mean          | 930          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 43           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 571          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018084628 |\n",
      "|    clip_fraction        | 0.0352       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.139       |\n",
      "|    explained_variance   | 0.48         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 9.59e+03     |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | 0.0036       |\n",
      "|    value_loss           | 1.74e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 35.2          |\n",
      "|    ep_rew_mean          | 1.01e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 43            |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 751           |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00087348727 |\n",
      "|    clip_fraction        | 0.0323        |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | -0.13         |\n",
      "|    explained_variance   | 0.486         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.59e+04      |\n",
      "|    n_updates            | 620           |\n",
      "|    policy_gradient_loss | 0.00249       |\n",
      "|    value_loss           | 1.74e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 35.4         |\n",
      "|    ep_rew_mean          | 965          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 41           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 990          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010956449 |\n",
      "|    clip_fraction        | 0.0324       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.134       |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.92e+03     |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | 0.00337      |\n",
      "|    value_loss           | 1.7e+04      |\n",
      "------------------------------------------\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/log_deadly_corridor\\PPO_5\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 17.4     |\n",
      "|    ep_rew_mean     | 289      |\n",
      "| time/              |          |\n",
      "|    fps             | 31       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 259      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.1        |\n",
      "|    ep_rew_mean          | 292         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 37          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 432         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032186113 |\n",
      "|    clip_fraction        | 0.0919      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.97e+04    |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | 0.02        |\n",
      "|    value_loss           | 2.94e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.4        |\n",
      "|    ep_rew_mean          | 292         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 576         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002136392 |\n",
      "|    clip_fraction        | 0.0595      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.01e+04    |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | 0.00353     |\n",
      "|    value_loss           | 2.56e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 17           |\n",
      "|    ep_rew_mean          | 274          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 37           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 863          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020227095 |\n",
      "|    clip_fraction        | 0.0481       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.238       |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.36e+04     |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | 0.00346      |\n",
      "|    value_loss           | 2.48e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.8        |\n",
      "|    ep_rew_mean          | 269         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 36          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 1122        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002277181 |\n",
      "|    clip_fraction        | 0.063       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.245      |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 8.9e+03     |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | 0.00386     |\n",
      "|    value_loss           | 2.48e+04    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, learning_rate=0.00001, n_steps=8192, clip_range=.1, gamma=.3, gae_lambda=.9)\n",
    "model.learn(total_timesteps=400000)\n",
    "model.save(\"./models/models_deadly_corridor/best_model_560000\")  # Save the model after training on the first skill level\n",
    "\n",
    "# Load the pre-trained model before training on each new skill level\n",
    "for skill_level in range(2, 6):\n",
    "    env = VizDoomGym(doom_skill=skill_level)\n",
    "    model = PPO.load(\"./models/models_deadly_corridor/best_model_560000\")  # Load the previously saved model\n",
    "    model.set_env(env)\n",
    "    model.learn(total_timesteps=40000)\n",
    "    model.save(\"./models/models_deadly_corridor/best_model_560000\")  # Save the model after training on the current skill level\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import eval policy to test agent\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload model from disc\n",
    "model = PPO.load('./models/models_deadly_corridor/best_model_560000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rendered environment\n",
    "env = VizDoomGym(render=True, doom_skill=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vibha\\miniconda3\\envs\\py38\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "190.9540786743164"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate mean reward for 10 games\n",
    "mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward for episode 1 is -472.9422607421875\n",
      "Total Reward for episode 2 is 360.46434020996094\n",
      "Total Reward for episode 3 is 434.45562744140625\n",
      "Total Reward for episode 4 is -248.23692321777344\n"
     ]
    }
   ],
   "source": [
    "for episode in range(100): \n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        time.sleep(0.20)\n",
    "        total_reward += reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode+1, total_reward))\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
